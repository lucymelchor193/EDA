{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4XyE5u1MCor"
      },
      "outputs": [],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Assignment- Explain Toeknization"
      ],
      "metadata": {
        "id": "DtZ9NYQRMRec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 types of tokenization\n",
        "#1. Word tokenization\n",
        "# 2. Sentence tokenization"
      ],
      "metadata": {
        "id": "j34nkzJdMRcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4 ways to tokenize in python\n",
        "1. Split function\n",
        "2.Regular expression\n",
        "3. NLTK\n",
        "4.SPACY"
      ],
      "metadata": {
        "id": "oXEBC6c8MRaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Split function"
      ],
      "metadata": {
        "id": "F-YOWsKGMRXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word tokenization\n",
        "sent1 = 'I am visitingt New york'\n",
        "sent1.split()"
      ],
      "metadata": {
        "id": "vc1vPglnMRVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split functions fails at following scenarios"
      ],
      "metadata": {
        "id": "oD72VOYiMRS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent2 = 'I am visiting to NEW YORK. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
        "sent2.split('.')"
      ],
      "metadata": {
        "id": "_p2U5XicMRQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent3 = 'I am visiting New york!'\n",
        "sent3.split()"
      ],
      "metadata": {
        "id": "Yj_9jqVpMRMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent3 = 'are you visiting new york?'\n",
        "sent3.split()"
      ],
      "metadata": {
        "id": "nkXNxK-NMRJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Regular expression"
      ],
      "metadata": {
        "id": "-hf56ktlMhe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove exclaimation !\n",
        "import re\n",
        "tokens = re.findall(\"[\\w']+\", sent3)\n",
        "tokens"
      ],
      "metadata": {
        "id": "_vW9AkHGMRHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to overcome all this challenges - Recommeded is to use library"
      ],
      "metadata": {
        "id": "w9hF-MQgMqpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library#1 NLTK"
      ],
      "metadata": {
        "id": "hFKktFlwMtK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "Kmv8f8xOMREU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent1)"
      ],
      "metadata": {
        "id": "7faKs24oM6H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent2)"
      ],
      "metadata": {
        "id": "IE2LXevKM6Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent3)"
      ],
      "metadata": {
        "id": "er02Is2PM6Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent5 =\"i drove 100km today\""
      ],
      "metadata": {
        "id": "jurkZaX6M5_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(sent5)"
      ],
      "metadata": {
        "id": "ma62-X0eM59d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library#2 SPACY"
      ],
      "metadata": {
        "id": "um7Tw1XxNBEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "UtV12ljWM56l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for spacy it is important that you convert your string to documents"
      ],
      "metadata": {
        "id": "GsoLUDOeM54E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 =nlp(sent1)"
      ],
      "metadata": {
        "id": "udXtXuh2M51U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 =nlp(sent2)"
      ],
      "metadata": {
        "id": "P3jc_W98M5yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc3 =nlp(sent3)"
      ],
      "metadata": {
        "id": "Hxd5yXi7M5vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc4 =nlp(sent5)\n"
      ],
      "metadata": {
        "id": "sWKElcDSNIp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc4:\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "XpBs20mwNInT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTENCE VS WORD TOKENIZATION"
      ],
      "metadata": {
        "id": "YlVGFwmcNIkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corp='''\n",
        "My anme is Parth,I live in toronto and I like to visit CN TOWER\n",
        "'''"
      ],
      "metadata": {
        "id": "1DuMpZA2NIh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# PARAGRAPH --> SENTENCE"
      ],
      "metadata": {
        "id": "7_PUV65fNIfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "vKVAmMgnNTUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "KnZbvuy1NTRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(corp)"
      ],
      "metadata": {
        "id": "PPW_MYaYNTOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check result with ! ,. ;"
      ],
      "metadata": {
        "id": "E4LgEOxDNTKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paragraph --> words\n"
      ],
      "metadata": {
        "id": "jSQ-AoDANTHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "hQYxPxbkNTEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corp)"
      ],
      "metadata": {
        "id": "TCIPev59NTBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corp)"
      ],
      "metadata": {
        "id": "qevxnt2-NS-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## more detailed tokenization"
      ],
      "metadata": {
        "id": "7eCbgHD5NSlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "goFVa-lfNdQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "Xn334WqRNdOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(corp)"
      ],
      "metadata": {
        "id": "EbMN5v1iNdLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "adhiKcpbNdJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(corp)"
      ],
      "metadata": {
        "id": "bhn52v43NdGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming Operation"
      ],
      "metadata": {
        "id": "IX2Rp24yNj55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porter stemmer"
      ],
      "metadata": {
        "id": "MUastF1RNlrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "mQLM9T2jNdDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming=PorterStemmer()"
      ],
      "metadata": {
        "id": "3jRaafVTNdAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=[\"drink\",\"drank\",\"drunk\",\"canada\",\"canadian\",\"finally\",\"finalized\",\"Marks\",\"history\",\"congratulations\", \"understanding\"]"
      ],
      "metadata": {
        "id": "35kvkzTeNp9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word+\":     :\"+stemming.stem(word))"
      ],
      "metadata": {
        "id": "9C85-nfmNp7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Lancaster Stemmer"
      ],
      "metadata": {
        "id": "Mdg7hHJRNtO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer"
      ],
      "metadata": {
        "id": "uKCi4ivzNp5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lancaster=LancasterStemmer()"
      ],
      "metadata": {
        "id": "pUvq0PtQNp3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word+\":     :\"+stemming.stem(word))"
      ],
      "metadata": {
        "id": "PcCq1yqtNp0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 Regex Stemmer\n"
      ],
      "metadata": {
        "id": "VlVdlrABNz3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utiltiy - remove suffix and prefix"
      ],
      "metadata": {
        "id": "vlHk9btrNpyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "140cXQqlNpvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer=RegexpStemmer('ing|s$|able$', min=4)"
      ],
      "metadata": {
        "id": "gP-uaPo6NptP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"ingplaying\")"
      ],
      "metadata": {
        "id": "XrXKNEfuNpre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"drinking\")"
      ],
      "metadata": {
        "id": "-PNJ81v4Npnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"understandable\")"
      ],
      "metadata": {
        "id": "MO9wBR2ENpky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem(\"fruits\")"
      ],
      "metadata": {
        "id": "ogAHBUdkN-6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 Snowball Stemmer\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GkWpvGI8OAnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "jvtk27AmN-24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## better output than porter stemmer"
      ],
      "metadata": {
        "id": "FftOIto7N-zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowballstemmer=SnowballStemmer('english',ignore_stopwords=False)"
      ],
      "metadata": {
        "id": "1AXFubLLN-vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+snowballstemmer.stem(word))"
      ],
      "metadata": {
        "id": "-ypfKhj-N-s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"happily\"),stemming.stem(\"foolishly\")"
      ],
      "metadata": {
        "id": "Y8Jxg86hN-qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowballstemmer.stem(\"happily\"),stemming.stem(\"foolishly\")"
      ],
      "metadata": {
        "id": "d-U64o5zOLNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem(\"fairly\")"
      ],
      "metadata": {
        "id": "92V9YZZZOLKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowballstemmer.stem(\"fairly\")"
      ],
      "metadata": {
        "id": "_-_6HYagOLHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zl27E4KROK5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "PNz7ibiKOKe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "WoaTEZKcORyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "gt4OZcfTOUX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word+\"---->\"+lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "O14zt1SZOUVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pos tag operation to find adverb, noun or anything"
      ],
      "metadata": {
        "id": "HQG3q56jOURw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "POS- Noun-n\n",
        "verb-v\n",
        "adjective-a\n",
        "adverb-r\n",
        "'''\n",
        "for word in words:\n",
        "    print(word+\"---->\"+lemmatizer.lemmatize(word,pos='v'))"
      ],
      "metadata": {
        "id": "xxVpaJ4dOUPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykr2dofxOUMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bj2Fg1KaOUJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}